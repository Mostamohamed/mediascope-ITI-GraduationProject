import requests
from bs4 import BeautifulSoup
import time
import re
import json
from urllib.parse import urljoin
from datetime import datetime
from kafka import KafkaProducer

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙƒØ§ÙÙƒØ§
producer = KafkaProducer(
    bootstrap_servers=['kafka:29092'],
    value_serializer=lambda x: json.dumps(x).encode('utf-8')
)

def get_tiktok_url_from_detail_page(tokchart_sound_url):
    """Ø³Ø­Ø¨ Ø±Ø§Ø¨Ø· ØªÙŠÙƒ ØªÙˆÙƒ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±"""
    try:
        response = requests.get(tokchart_sound_url, timeout=10)
        if response.status_code != 200: return None
    except: return None

    soup = BeautifulSoup(response.content, 'html.parser')
    tiktok_link = soup.find('a', href=re.compile("tiktok\.com/music/"))
    
    if tiktok_link:
        return tiktok_link['href']
    else:
        tiktok_link_text = soup.find('a', string="View on TikTok")
        if tiktok_link_text and 'href' in tiktok_link_text.attrs:
             return tiktok_link_text['href']
        return None


# --- Ø¯ÙˆØ§Ù„ Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ---
def clean_ugc(text):
    """ØªÙ†Ø¸ÙŠÙ Ø±Ù‚Ù… Ø§Ù„Ù€ UGC ÙˆØ§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø±Ù‚Ù… Ø§Ù„Ø¯Ù‚ÙŠÙ‚"""
    # Ø§Ù„Ù†Øµ Ø¨ÙŠØ¬ÙŠ ÙƒØ¯Ù‡: "1K\n 1,247"
    # Ù‡Ù†Ù‚Ø³Ù… Ø§Ù„Ù†Øµ Ù…Ø³Ø§ÙØ§Øª ÙˆÙ†Ø§Ø®Ø¯ Ø¢Ø®Ø± Ø¬Ø²Ø¡ Ù„Ø£Ù†Ù‡ ØºØ§Ù„Ø¨Ø§Ù‹ Ø§Ù„Ø±Ù‚Ù… Ø§Ù„Ø¯Ù‚ÙŠÙ‚
    parts = text.split()
    if not parts: return "0"
    return parts[-1] # Ù‡ÙŠØ±Ø¬Ø¹ 1,247

# def clean_growth(text):
#     """ØªÙ†Ø¸ÙŠÙ Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ù…Ùˆ ÙˆØ§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø¦ÙˆÙŠØ©"""
#     # Ø§Ù„Ù†Øµ Ø¨ÙŠØ¬ÙŠ ÙƒØ¯Ù‡: "+238\n +30.87\n %"
#     parts = text.split()
#     if not parts: return "0%"
    
#     # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø¦ÙˆÙŠØ© Ù„Ùˆ Ù…ÙØµÙˆÙ„Ø©
#     if parts[-1] == '%':
#         return f"{parts[-2]}%" # Ù‡ÙŠØ±Ø¬Ø¹ +30.87%
    
#     # Ù„Ùˆ Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ø§Ø²Ù‚Ø© ÙÙŠ Ø§Ù„Ø±Ù‚Ù…
#     for p in parts:
#         if '%' in p: return p
        
#     return parts[-1]

def clean_growth(text):
    """
    Ø³Ø­Ø¨ Ø±Ù‚Ù… Ø§Ù„Ù†Ù…Ùˆ Ø§Ù„ÙŠÙˆÙ…ÙŠ (Ø§Ù„Ø±Ù‚Ù… Ø§Ù„Ø£ÙˆÙ„) ÙˆØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø¦ÙˆÙŠØ©
    Input Example: "+6,500\n +8.13 %"
    Output: "+6,500"
    """
    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª ÙˆØ§Ù„Ø£Ø³Ø·Ø± Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
    parts = text.split()
    
    if not parts: 
        return "0"
    
    # Ø§Ø­Ù†Ø§ Ø¹Ø§ÙŠØ²ÙŠÙ† Ø§Ù„Ø±Ù‚Ù… Ø§Ù„Ù„ÙŠ ÙÙˆÙ‚ (Ø£ÙˆÙ„ ÙˆØ§Ø­Ø¯ ÙÙŠ Ø§Ù„Ù„ÙŠØ³Øª)
    return parts[0]


def scrape_and_send(num_pages=1):
    """Ø³Ø­Ø¨ Ø§Ù„Ø¯Ø§ØªØ§ ÙˆØ¥Ø±Ø³Ø§Ù„Ù‡Ø§ Ù„Ù€ Kafka Ù…Ø¨Ø§Ø´Ø±Ø©"""
    base_url = 'https://tokchart.com/dashboard/tiktok-trending-sounds/EG'
    
    print(f"ğŸµ Starting TikTok Scrape for {num_pages} pages...")

    for page_num in range(1, num_pages + 1):
        page_url = f"{base_url}?page={page_num}"
        try:
            response = requests.get(page_url)
            if response.status_code != 200: continue
            
            soup = BeautifulSoup(response.content, 'html.parser')
            table = soup.find('table')
            if not table: continue
            
            rows = table.find('tbody').find_all('tr')
            
            for row in rows:
                cells = row.find_all('td')
                if len(cells) > 7:
                    sound_cell = cells[1]
                    sound_link = sound_cell.find('a', href=True)
                    
                    if sound_link:
                        relative_url = sound_link['href']
                        tokchart_detail_url = urljoin("https://tokchart.com", relative_url)
                        
                        direct_link = get_tiktok_url_from_detail_page(tokchart_detail_url)
                        fetch_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

                        # Ù‡Ù†Ø§ Ø§Ù„ØªØºÙŠÙŠØ±: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¯ÙˆØ§Ù„ Ø§Ù„ØªÙ†Ø¸ÙŠÙ
                        raw_ugc = cells[2].text.strip()
                        raw_growth = cells[3].text.strip()

                        payload = {
                            "rank": cells[0].text.strip(),
                            "sound_name": sound_cell.get_text(strip=True),
                            "ugc_count": clean_ugc(raw_ugc),      # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù€ UGC
                            "growth": clean_growth(raw_growth),   # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù€ Growth
                            "author_country": cells[4].text.strip(),
                            "tokchart_url": tokchart_detail_url,
                            "tiktok_direct_url": direct_link if direct_link else "Not Found",
                            "fetch_timestamp": fetch_time
                        }
                        
                        producer.send('tiktok_data', value=payload)
                        print(f"Sent: {payload['sound_name']} | UGC: {payload['ugc_count']} | Growth: {payload['growth']}")
                        
                        time.sleep(0.5)
            
            print(f"âœ… Page {page_num} finished.")
            time.sleep(1)

        except Exception as e:
            print(f"âŒ Error on page {page_num}: {e}")

# def scrape_and_send(num_pages=5):
#     """Ø³Ø­Ø¨ Ø§Ù„Ø¯Ø§ØªØ§ ÙˆØ¥Ø±Ø³Ø§Ù„Ù‡Ø§ Ù„Ù€ Kafka Ù…Ø¨Ø§Ø´Ø±Ø©"""
#     base_url = 'https://tokchart.com/dashboard/tiktok-trending-sounds/EG'
    
#     print(f"ğŸµ Starting TikTok Scrape for {num_pages} pages...")

#     for page_num in range(1, num_pages + 1):
#         page_url = f"{base_url}?page={page_num}"
#         try:
#             response = requests.get(page_url)
#             if response.status_code != 200: continue
            
#             soup = BeautifulSoup(response.content, 'html.parser')
#             table = soup.find('table')
#             if not table: continue
            
#             rows = table.find('tbody').find_all('tr')
            
#             for row in rows:
#                 cells = row.find_all('td')
#                 if len(cells) > 7:
#                     sound_cell = cells[1]
#                     sound_link = sound_cell.find('a', href=True)
                    
#                     if sound_link:
#                         relative_url = sound_link['href']
#                         tokchart_detail_url = urljoin("https://tokchart.com", relative_url)
                        
#                         # Ø³Ø­Ø¨ Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
#                         direct_link = get_tiktok_url_from_detail_page(tokchart_detail_url)
                        
#                         # ÙˆÙ‚Øª Ø§Ù„Ø³Ø­Ø¨ (Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹)
#                         fetch_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

#                         # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¯Ø§ØªØ§
#                         payload = {
#                             "rank": cells[0].text.strip(),
#                             "sound_name": sound_cell.get_text(strip=True),
#                             "ugc_count": cells[2].text.strip(),
#                             "growth": cells[3].text.strip(),
#                             "author_country": cells[4].text.strip(),
#                             "tokchart_url": tokchart_detail_url,
#                             "tiktok_direct_url": direct_link if direct_link else "Not Found",
#                             "fetch_timestamp": fetch_time # Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù„ÙŠ Ø·Ù„Ø¨ØªÙ‡
#                         }
                        
#                         # Ø¥Ø±Ø³Ø§Ù„ Ù„Ù€ Kafka
#                         producer.send('tiktok_data', value=payload)
#                         print(f"Sent: {payload['sound_name']}")
                        
#                         time.sleep(0.5) # Ø§Ø­ØªØ±Ø§Ù… Ø§Ù„Ù…ÙˆÙ‚Ø¹
            
#             print(f"âœ… Page {page_num} finished.")
#             time.sleep(1)

#         except Exception as e:
#             print(f"âŒ Error on page {page_num}: {e}")

def run_scheduler():
    while True:
        print(f"â° Starting Daily Job at {datetime.now()}")
        
        # Ø´ØºÙ„ Ø§Ù„Ø³ÙƒØ±Ø§Ø¨ÙŠÙ†Ø¬ (ØµÙØ­ØªÙŠÙ† ÙƒÙØ§ÙŠØ© Ù„Ù„ØªØ¬Ø±Ø¨Ø©)
        scrape_and_send(num_pages=1)
        
        print("ğŸ’¤ Job finished. Sleeping for 24 hours...")
        # Ù‡Ù†Ø§ Ù‡ÙŠÙ†Ø§Ù… ÙŠÙˆÙ… ÙƒØ§Ù…Ù„ (86400 Ø«Ø§Ù†ÙŠØ©)
        # Ù„Ùˆ Ø¹Ø§ÙŠØ² ØªØ¬Ø±Ø¨ØŒ ØºÙŠØ± Ø§Ù„Ø±Ù‚Ù… Ø¯Ù‡ Ù„Ù€ 60 (Ø¯Ù‚ÙŠÙ‚Ø©)
        time.sleep(86400)

if __name__ == "__main__":
    run_scheduler()